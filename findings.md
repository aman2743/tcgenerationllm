# Research & Findings

## Current Understanding
- Goal: Create a local LLM Testcase generator using Ollama (Llama 3.2).
- Protocol: B.L.A.S.T. (Blueprint, Link, Architect, Stylize, Trigger).

## Discovery Answers
- **North Star**: Local LLM test cases generator (Llama 3.2) with a stored template.
- **Integrations**: Ollama (Local API).
- **Source of Truth**: User Input via UI.
- **Delivery Payload**: Web-based Chat UI.
- **Behavioral Rules**: User Input -> Applied to Template -> Ollama -> Test Cases Output.
